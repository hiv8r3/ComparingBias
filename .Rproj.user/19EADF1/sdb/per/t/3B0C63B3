{
    "collab_server" : "",
    "contents" : "---\ntitle: Observer analyses\nauthor: Hannah, 5/16/2017\noutput:\n  html_document:\n    highlight: pygments\n    theme: cerulean\n  pdf_document: default\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\noptions(width=140)\nrequire(dplyr)\nrequire(ggplot2)\nrequire(lme4)\nrequire(lmerTest)\nrequire(knitr)\nrequire(reshape2)\n```\n\nData for Study 1 was collected in Fall 2015. Data for Study 2 was collected in Fall 2016 (hypotheses were preregistered at aspredicted.org).\n\n**In Study 1:**  \n- 101 subjects participated  \n- 8 subjects' AP data was discarded (see \"Study1_badsubsAP.txt\")  \n- 9 subjects' WIT data was discarded (see \"Study1_badsubsWIT.txt\")    \n*This left 93 subjects with AP data and 92 subjects with WIT data.*\n\nAdditionally, IMS/EMS data is missing for subs 3, 27, 53, 82, 88, 89, 90, and 101. \n\n**In Study 2:**  \n- 206 subjects participated  \n- 8 subjects' AP data was discarded (see \"Study2_badsubsAP.txt\")  \n- 7 subjects' WIT data was discarded (see \"Study2_badsubsWIT.txt\")  \n*This left 198 subjects with AP data and 199 subjects with WIT data.*\n\nAdditionally, IMS/EMS data is missing for 111, 189, and 201.\n\nThere were 48 trials for each condition in each task. In Study 2, each task was split into two sections so that participants could answer anxiety questions in the middle and end of each task.\n\n### 1. Accuracy in each task:  \n#### 2 (Prime: Black/White) x 2 (Target: gun/tool or positive/negative) rANOVA  \nOnly showing interaction indicating racial bias (Prime x Target). For calculation of effect sizes, see \"7 Effect sizes.R\"  \n#### Study 1:  \n**WIT**  \n```{r data, echo = FALSE}\n# For analyses with accuracy as DV, need trials to be grouped into conditions (ie number of errors in each condition)\ns1.acc = read.delim(\"Study1_errCountLong.txt\")\n\n# separate by task\ns1.acc.AP = s1.acc[s1.acc$Task == \"AP\",]\ns1.acc.WIT = s1.acc[s1.acc$Task == \"WIT\",]\n\ns1.acc.AP$TargetType = factor(s1.acc.AP$TargetType)\ns1.acc.WIT$TargetType = factor(s1.acc.WIT$TargetType)\ns1.acc.AP$Subject = factor(s1.acc.AP$Subject)\ns1.acc.WIT$Subject = factor(s1.acc.WIT$Subject)\n\n# Race x Valence on accuracy (WIT)\nsum = aov(numErr ~ PrimeType*TargetType + Error(Subject/(PrimeType*TargetType)), data = s1.acc.WIT) %>% \n  summary()\n\nsum$`Error: Subject:PrimeType:TargetType`\n\n```\n\n**AP**\n``` {r AP, echo = FALSE}\n# Race x Valence on accuracy (WIT)\nsum = aov(numErr ~ PrimeType*TargetType*Observer + Error(Subject/(PrimeType*TargetType)), data = s1.acc.AP) %>% \n  summary()\n\nsum$`Error: Subject:PrimeType:TargetType`\n```\n\n\n#### Study 2: \nOnly showing interaction indicating racial bias (Prime x Target). For calculation of effect sizes, see \"7 Effect sizes.R\"  \n**WIT**  \n```{r data2, echo = FALSE}\n# For analyses with accuracy as DV, need trials to be grouped into conditions (ie number of errors in each condition)\ns2.acc = read.delim(\"Study2_errCountLong.txt\")\n\n# separate by task\ns2.acc.AP = s2.acc[s2.acc$Task == \"AP\",]\ns2.acc.WIT = s2.acc[s2.acc$Task == \"WIT\",]\n\ns2.acc.AP$TargetType = factor(s2.acc.AP$TargetType)\ns2.acc.WIT$TargetType = factor(s2.acc.WIT$TargetType)\ns2.acc.AP$Subject = factor(s2.acc.AP$Subject)\ns2.acc.WIT$Subject = factor(s2.acc.WIT$Subject)\n\n# Race x Valence on accuracy (WIT)\nsum = aov(numErr ~ PrimeType*TargetType + Error(Subject/(PrimeType*TargetType)), data = s2.acc.WIT) %>% \n  summary()\n\nsum$`Error: Subject:PrimeType:TargetType`\n```\n\n**AP**\n``` {r AP2, echo = FALSE}\n# Race x Valence on accuracy (WIT)\nsum = aov(numErr ~ PrimeType*TargetType + Error(Subject/(PrimeType*TargetType)), data = s2.acc.AP) %>% \n  summary()\n\nsum$`Error: Subject:PrimeType:TargetType`\n```\n\n### 2. Comparing accuracy across tasks\n##### - Correlation between performance bias scores\n##### - Look at 3 way Prime x Target x Task interaction\n\n#### Study 1\nExcludes subjects that don't have data in both tasks (only includes sample of 90).  \n\n#### A. Correlation between performance bias scores on each task\n``` {r perfBias.s1, echo=F, warning=F}\ns1.perfBias = read.delim(\"Study1_perfBias.txt\")\n\n# Look at correlation between tasks\nggplot(s1.perfBias, aes(APStand, WITStand)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") + \n  #  ggtitle(\"Correlation between accuracy on WIT and accuracy on AP\") +\n  labs(x = \"Stand. Performance bias on AP\", y = \"Stand. Performance bias on WIT\") +\n  theme_bw()+\n  theme(axis.title.x = element_text(size=20),\n        axis.title.y = element_text(size=20),\n        title = element_text(size=20)\n        #axis.text.x  = element_text(angle=90, vjust=0.5, size=16)\n  )\n\nlm(APStand ~ WITStand, data = s1.perfBias) %>%\n  summary()\n```\n\n#### B. Examine 3 way Prime x Target x Task interaction  \n``` {r 3way.s1, echo=F, wanring=F}\n# Look just at subjects that have data for both tasks, otherwise throws error (\"Error() model is singular\")\n# Probably because some subjects don't have data across both levels of task\ns1.bsWIT = read.delim(\"Study1_badsubsWIT.txt\")\ns1.bsAP = read.delim(\"Study1_badsubsAP.txt\")\ns1.acc.nobs = s1.acc[!(s1.acc$Subject %in% s1.bsWIT$Subject) & !(s1.acc$Subject %in% s1.bsAP$Subject),]\ns1.acc.nobs$Subject = factor(s1.acc.nobs$Subject)\n\n# Total number of errors (looking at three-way interaction)\nfacet_labels <- c(AP = \"APT\", WIT = \"WIT\")\n\n# Figure 1 ----------------------------------------------------------------\nggplot(s1.acc.nobs, aes(PrimeType, (48-numErr)/48, fill = ConType)) +\n  stat_summary(fun.y = mean, geom = \"bar\", position = \"dodge\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", position = position_dodge(width=.9), width = .2) +\n  facet_wrap(~Task, labeller=labeller(Task = facet_labels)) + \n  #  ggtitle(\"Total number of errors\") +\n  labs(y = \"Accuracy rate\", x = \"Race of Prime\") +\n  scale_fill_manual(values=c(\"black\",\"grey70\"), guide = guide_legend(title = NULL)) +\n  theme_bw() +\n  theme(panel.grid.major = element_line(color = \"white\"),\n        panel.grid.minor = element_line(color = \"white\"),\n        strip.text.x = element_text(face = \"bold\", size = 14),\n        strip.background = element_rect(fill = \"grey98\"),\n        axis.text.x = element_text(size = 14),\n        axis.text.y = element_text(size = 14),\n        axis.title.x = element_text(size = 14),\n        axis.title.y = element_text(size = 14))\n\nggsave(\"./Figures/Accuracy_Study1.tiff\")\n\n\n# See if pattern of racial bias differs across two tasks- TOTAL ERRORS\nsum2 = aov(numErr ~ (PrimeType*ConType*Task)+Error(Subject/(PrimeType*ConType*Task)), data = s1.acc.nobs) %>%\n  summary()\n\nsum2$`Error: Subject:PrimeType:ConType:Task`\n\n```\n\n#### Study 2\nExcludes subjects that don't have data in both tasks (only includes sample of 195).  \n\n#### A. Correlation between performance bias scores on each task\n``` {r perfBias.s2, echo=F, warning=F}\ns2.perfBias = read.delim(\"Study2_perfBias.txt\")\n\n# Look at correlation between tasks\nggplot(s2.perfBias, aes(APStand, WITStand)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") + \n  #  ggtitle(\"Correlation between accuracy on WIT and accuracy on AP\") +\n  labs(x = \"Stand. Performance bias on AP\", y = \"Stand. Performance bias on WIT\") +\n  theme_bw()+\n  theme(axis.title.x = element_text(size=20),\n        axis.title.y = element_text(size=20),\n        title = element_text(size=20)\n        #axis.text.x  = element_text(angle=90, vjust=0.5, size=16)\n  )\n\nlm(APStand ~ WITStand, data = s2.perfBias) %>%\n  summary()\n```\n\n#### B. Examine 3 way Prime x Target x Task interaction  \n``` {r 3way.s2, echo=F, wanring=F}\n# Look just at subjects that have data for both tasks, otherwise throws error (\"Error() model is singular\")\n# Probably because some subjects don't have data across both levels of task\ns2.bsWIT = read.delim(\"Study2_badsubsWIT.txt\")\ns2.bsAP = read.delim(\"Study2_badsubsAP.txt\")\ns2.acc.nobs = s2.acc[!(s2.acc$Subject %in% s2.bsWIT$Subject) & !(s2.acc$Subject %in% s2.bsAP$Subject),]\ns2.acc.nobs$Subject = factor(s2.acc.nobs$Subject)\n\n# Total number of errors (looking at three-way interaction)\nfacet_labels <- c(AP = \"APT\", WIT = \"WIT\")\n\n# Figure 1 ----------------------------------------------------------------\nggplot(s2.acc.nobs, aes(PrimeType, (48-numErr)/48, fill = ConType)) +\n  stat_summary(fun.y = mean, geom = \"bar\", position = \"dodge\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", position = position_dodge(width=.9), width = .2) +\n  facet_wrap(~Task, labeller=labeller(Task = facet_labels)) + \n  #  ggtitle(\"Total number of errors\") +\n  labs(y = \"Accuracy rate\", x = \"Race of Prime\") +\n  scale_fill_manual(values=c(\"black\",\"grey70\"), guide = guide_legend(title = NULL)) +\n  theme_bw() +\n  theme(panel.grid.major = element_line(color = \"white\"),\n        panel.grid.minor = element_line(color = \"white\"),\n        strip.text.x = element_text(face = \"bold\", size = 14),\n        strip.background = element_rect(fill = \"grey98\"),\n        axis.text.x = element_text(size = 14),\n        axis.text.y = element_text(size = 14),\n        axis.title.x = element_text(size = 14),\n        axis.title.y = element_text(size = 14))\n\nggsave(\"./Figures/Accuracy_Study2.tiff\")\n\n\n# See if pattern of racial bias differs across two tasks- TOTAL ERRORS\nsum2 = aov(numErr ~ (PrimeType*ConType*Task)+Error(Subject/(PrimeType*ConType*Task)), data = s2.acc.nobs) %>%\n  summary()\n\nsum2$`Error: Subject:PrimeType:ConType:Task`\n\n```\n\n### 3. Look at correlations between PDP estimates\n\n####Study 1:  \n``` {r correl, echo=F}\n# compare PDP-C estimates across tasks\ns1.widePDP = read.delim(\"Study1_PDP_wide.txt\")\n\n# C estimates\nggplot(s1.widePDP, aes(WIT_MeanC.stand, AP_MeanC.stand)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  #  ggtitle(\"Correlation between accuracy on WIT and accuracy on AP\") +\n  labs(x = \"WIT PDP-C\", y = \"AP PDP-C\") +\n  theme_bw()+\n  theme(axis.title.x = element_text(size=20),\n        axis.title.y = element_text(size=20),\n        title = element_text(size=20)\n        #axis.text.x  = element_text(angle=90, vjust=0.5, size=16)\n  )\n\nlm(WIT_MeanC.stand ~ AP_MeanC.stand, data = s1.widePDP) %>% summary()\n\n# A estimates\nggplot(s1.widePDP, aes(WIT_AResid.stand, AP_AResid.stand)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  #  ggtitle(\"Correlation between accuracy on WIT and accuracy on AP\") +\n  labs(x = \"WIT PDP-A\", y = \"AP PDP-A\") +\n  theme_bw()+\n  theme(axis.title.x = element_text(size=20),\n        axis.title.y = element_text(size=20),\n        title = element_text(size=20)\n        #axis.text.x  = element_text(angle=90, vjust=0.5, size=16)\n  )\n\nlm(WIT_AResid.stand ~ AP_AResid.stand, data = s1.widePDP) %>% summary()\n\n# Compare C and A resid \ntempC = select(s1.widePDP, Subject, WIT_MeanC.stand, AP_MeanC.stand) %>% \n  rename(WITestimate = WIT_MeanC.stand, APTestimate = AP_MeanC.stand)\ntempC$Type = \"PDP-C\"\n\ntempA = select(s1.widePDP, Subject, WIT_AResid.stand, AP_AResid.stand) %>% \n  rename(WITestimate = WIT_AResid.stand, APTestimate = AP_AResid.stand)\ntempA$Type = \"PDP-A\"\n\ncompareAC = rbind(tempC, tempA)\ncompareAC$Type = factor(compareAC$Type)\n\nggplot(compareAC, aes(WITestimate, APTestimate, pch = Type)) +\n  geom_point(aes(shape = Type), size = 2.5, alpha = .7) +\n  scale_shape_manual(values=c(1,17)) +\n  scale_linetype_manual(values=c(\"solid\", \"dashed\")) +\n  theme_bw() +\n  geom_smooth(method = \"lm\", aes(linetype=Type), color = \"black\") +\n  labs(x = \"PDP estimates for WIT\", y = \"PDP estimates for APT\") +\n  theme(panel.grid.major = element_line(color = \"white\"),\n        panel.grid.minor = element_line(color = \"white\"),\n        legend.title = element_blank(),\n        legend.key.size = unit(1.2, \"cm\"),\n        axis.title.x = element_text(size=20),\n        axis.title.y = element_text(size=20),\n        axis.text.x = element_text(size=16),\n        axis.text.y = element_text(size=16))+\n  coord_cartesian(ylim=c(-2.5,3), xlim=c(-2.5,3))\n\nggsave(\"./Figures/CompareAC_Study1.tiff\")\n\nlm(WITestimate ~ APTestimate*Type, data = compareAC) %>% summary()\n\n```\n\n####Study 2:  \n``` {r correl2, echo=F}\n# compare PDP-C estimates across tasks\ns2.widePDP = read.delim(\"Study2_PDP_wide.txt\")\n\n# C estimates\nggplot(s2.widePDP, aes(WIT_MeanC.stand, AP_MeanC.stand)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  #  ggtitle(\"Correlation between accuracy on WIT and accuracy on AP\") +\n  labs(x = \"WIT PDP-C\", y = \"AP PDP-C\") +\n  theme_bw()+\n  theme(axis.title.x = element_text(size=20),\n        axis.title.y = element_text(size=20),\n        title = element_text(size=20)\n        #axis.text.x  = element_text(angle=90, vjust=0.5, size=16)\n  )\n\nlm(WIT_MeanC.stand ~ AP_MeanC.stand, data = s2.widePDP) %>% summary()\n\n# A estimates\nggplot(s2.widePDP, aes(WIT_AResid.stand, AP_AResid.stand)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  #  ggtitle(\"Correlation between accuracy on WIT and accuracy on AP\") +\n  labs(x = \"WIT PDP-A\", y = \"AP PDP-A\") +\n  theme_bw()+\n  theme(axis.title.x = element_text(size=20),\n        axis.title.y = element_text(size=20),\n        title = element_text(size=20)\n        #axis.text.x  = element_text(angle=90, vjust=0.5, size=16)\n  )\n\nlm(WIT_AResid.stand ~ AP_AResid.stand, data = s2.widePDP) %>% summary()\n\n# Compare C and A resid \ntempC = select(s2.widePDP, Subject, WIT_MeanC.stand, AP_MeanC.stand) %>% \n  rename(WITestimate = WIT_MeanC.stand, APTestimate = AP_MeanC.stand)\ntempC$Type = \"PDP-C\"\n\ntempA = select(s2.widePDP, Subject, WIT_AResid.stand, AP_AResid.stand) %>% \n  rename(WITestimate = WIT_AResid.stand, APTestimate = AP_AResid.stand)\ntempA$Type = \"PDP-A\"\n\ncompareAC = rbind(tempC, tempA)\ncompareAC$Type = factor(compareAC$Type)\n\nggplot(compareAC, aes(WITestimate, APTestimate, pch = Type)) +\n  geom_point(aes(shape = Type), size = 2.5, alpha = .7) +\n  scale_shape_manual(values=c(1,17)) +\n  scale_linetype_manual(values=c(\"solid\", \"dashed\")) +\n  theme_bw() +\n  geom_smooth(method = \"lm\", aes(linetype=Type), color = \"black\") +\n  labs(x = \"PDP estimates for WIT\", y = \"PDP estimates for APT\") +\n  theme(panel.grid.major = element_line(color = \"white\"),\n        panel.grid.minor = element_line(color = \"white\"),\n        legend.title = element_blank(),\n        legend.key.size = unit(1.2, \"cm\"),\n        axis.title.x = element_text(size=20),\n        axis.title.y = element_text(size=20),\n        axis.text.x = element_text(size=16),\n        axis.text.y = element_text(size=16)) +\n  coord_cartesian(ylim=c(-2.5,3), xlim=c(-2.5,3))\n\nggsave(\"./Figures/CompareAC_Study2.tiff\")\n\nlm(WITestimate ~ APTestimate*Type, data = compareAC) %>% summary()\n```\n\n### 4. Test Observer x IMS interaction on three criterion (response accuracy bias, PDP-C, and PDP-A)  \n**IMS is standardized for models, although not in plots. Models give unstandardized estimates.**  \n#####Study 1:  \n``` {r obsIMS1, echo=F, warning=F}\n\nWIT = select(s1.widePDP, Subject, Observer, WIT_MeanC, WIT_AResid) %>% \n  rename(MeanC = WIT_MeanC, AResid = WIT_AResid)\nWIT$Task = \"WIT\"\n\nAPT = select(s1.widePDP, Subject, Observer, APT_MeanC, APT_AResid) %>% \n  rename(MeanC = APT_MeanC, AResid = APT_AResid)\nAPT$Task = \"APT\"\n\n# put them together\ns1.wide = rbind(WIT, APT)\n\n# add IMS data\nIMS = read.delim(\"Study1_experimentalTrials.txt\") %>% \n  filter(blockName == \"WIT\", SubTrial == 1) %>% \n  select(Subject, IMS)\n\ns1.wide$IMS = NA\nfor (k in IMS$Subject[!(is.na(IMS$IMS))]) {\n  s1.wide$IMS[s1.wide$Subject == k] = IMS$IMS[IMS$Subject == k]\n}\n\n# add response accuracy data\ns1.wide$perfBias = NA\nfor (k in unique(s1.perfBias$Subject)) {\n  s1.wide$perfBias[s1.wide$Subject == k & s1.wide$Task == \"WIT\"] = s1.perfBias$WITperfBias[s1.perfBias$Subject == k]\n  s1.wide$perfBias[s1.wide$Subject == k & s1.wide$Task == \"APT\"] = s1.perfBias$APperfBias[s1.perfBias$Subject == k]  \n}\n\n# Perf bias\nggplot(s1.wide, aes(IMS, perfBias, color=Observer)) +\n  facet_wrap(~Task) +\n  geom_point()+\n  geom_smooth(method=\"lm\") +\n  theme_bw() +\n  scale_color_manual(values=c(\"darkgreen\", \"green\")) +\n  ylab(\"Performance bias\") +\n  theme(plot.title=element_text(hjust=.5))\n\nggsave(\"Figures/ObsXIMS_perfBias_Study1.tiff\", width = 8, height = 4)\n\n# PDP control\nggplot(s1.wide, aes(IMS, MeanC, color=Observer)) +\n  facet_wrap(~Task) +\n  geom_point()+\n  geom_smooth(method=\"lm\") +\n  theme_bw() +\n  scale_color_manual(values=c(\"purple4\", \"orchid2\")) +\n  ylab(\"PDP control estimate\") +\n  theme(plot.title=element_text(hjust=.5))\n\nggsave(\"Figures/ObsXIMS_PDPcontrol_Study1.tiff\", width = 8, height = 4)\n\n# PDP auto\nggplot(s1.wide, aes(IMS, AResid, color=Observer)) +\n  facet_wrap(~Task)+\n  geom_point()+\n  geom_smooth(method=\"lm\") +\n  theme_bw() +\n  scale_color_manual(values=c(\"red4\", \"tomato\")) +\n  ylab(\"PDP auto estimate\") +\n  theme(plot.title=element_text(hjust=.5))\n\nggsave(\"Figures/ObsXIMS_PDPauto_Study1.tiff\", width = 8, height = 4)\n\nm1 = lm(perfBias ~ scale(IMS)*Observer*Task, data = s1.wide) %>% \n  summary()\nm2 = lm(MeanC ~ scale(IMS)*Observer*Task, data = s1.wide) %>% \n  summary()\nm3 = lm(AResid ~ scale(IMS)*Observer*Task, data = s1.wide) %>% \n  summary()\n\n\n\n```\n\n**Perf bias:**\n\n``` {r table1, echo=F}\nkable(m1$coefficients)\n```\n\n**PDP-C estimates:**\n\n``` {r table2, echo=F}\nkable(m2$coefficients)\n```\n\n**PDP-A estimates:**\n\n``` {r table3, echo=F}\nkable(m3$coefficients)\n```\n\n``` {r followup, echo=T}\n# Look at each level of observer separately\n## Present\nlm(AResid ~ scale(IMS)*Task, data = s1.wide[s1.wide$Observer == \"Present\",]) %>%\n  summary()\n## Absent\nlm(AResid ~ scale(IMS)*Task, data = s1.wide[s1.wide$Observer == \"Absent\",]) %>%\n  summary()\n\n# simple slopes\nlm(scale(AResid) ~ scale(IMS), data = s1.wide[s1.wide$Observer == \"Present\" & s1.wide$Task == \"APT\",]) %>%\n  summary()\nlm(scale(AResid) ~ scale(IMS), data = s1.wide[s1.wide$Observer == \"Present\" & s1.wide$Task == \"WIT\",]) %>%\n  summary()\n\n```\n\n#####Study 2: \n``` {r obsIMS2, echo=F, warning=F}\n# read in PDP estimates in wide format\n\nWIT = select(s2.widePDP, Subject, Observer, WIT_MeanC, WIT_AResid) %>% \n  rename(MeanC = WIT_MeanC, AResid = WIT_AResid)\nWIT$Task = \"WIT\"\n\nAPT = select(s2.widePDP, Subject, Observer, APT_MeanC, APT_AResid) %>% \n  rename(MeanC = APT_MeanC, AResid = APT_AResid)\nAPT$Task = \"APT\"\n\n# put them together\ns2.wide = rbind(WIT, APT)\n\n# add IMS data\nIMS = read.delim(\"Study2_experimentalTrials.txt\") %>% \n  filter(blockName == \"WIT_1\", SubTrial == 1) %>% \n  select(Subject, IMS)\n\ns2.wide$IMS = NA\nfor (k in IMS$Subject[!(is.na(IMS$IMS))]) {\n  s2.wide$IMS[s2.wide$Subject == k] = IMS$IMS[IMS$Subject == k]\n}\n\n# add response accuracy data\ns2.wide$perfBias = NA\nfor (k in unique(s2.perfBias$Subject)) {\n  s2.wide$perfBias[s2.wide$Subject == k & s2.wide$Task == \"WIT\"] = s2.perfBias$WITperfBias[s2.perfBias$Subject == k]\n  s2.wide$perfBias[s2.wide$Subject == k & s2.wide$Task == \"APT\"] = s2.perfBias$APperfBias[s2.perfBias$Subject == k]  \n}\n\n# Perf bias\nggplot(s2.wide, aes(IMS, perfBias, color=Observer)) +\n  facet_wrap(~Task) +\n  geom_point()+\n  geom_smooth(method=\"lm\") +\n  theme_bw() +\n  scale_color_manual(values=c(\"darkgreen\", \"green\")) +\n  ylab(\"Performance bias\") +\n  theme(plot.title=element_text(hjust=.5))\n\nggsave(\"Figures/ObsXIMS_perfBias_Study2.tiff\", width = 8, height = 4)\n\n\n# PDP control\nggplot(s2.wide, aes(IMS, MeanC, color=Observer)) +\n  facet_wrap(~Task) +\n  geom_point()+\n  geom_smooth(method=\"lm\") +\n  theme_bw() +\n  scale_color_manual(values=c(\"purple4\", \"orchid2\")) +\n  ylab(\"PDP control estimate\") +\n  theme(plot.title=element_text(hjust=.5))\n\nggsave(\"Figures/ObsXIMS_PDPcontrol_Study2.tiff\", width = 8, height = 4)\n\n# PDP auto\nggplot(s2.wide, aes(IMS, AResid, color=Observer)) +\n  facet_wrap(~Task)+\n  geom_point()+\n  geom_smooth(method=\"lm\") +\n  theme_bw() +\n  scale_color_manual(values=c(\"red4\", \"tomato\")) +\n  ylab(\"PDP auto estimate\") +\n  theme(plot.title=element_text(hjust=.5))\n\nggsave(\"Figures/ObsXIMS_PDPauto_Study2.tiff\", width = 8, height = 4)\n\nm4 = lm(perfBias ~ scale(IMS)*Observer*Task + (1|Subject), data = s2.wide) %>% \n  summary()\nm5 = lm(MeanC ~ scale(IMS)*Observer*Task + (1|Subject), data = s2.wide) %>% \n  summary()\nm6 = lm(AResid ~ scale(IMS)*Observer*Task + (1|Subject), data = s2.wide) %>% \n  summary()\n\n```\n\n**Perf bias:**\n\n``` {r table4, echo=F}\nkable(m4$coefficients)\n```\n\n**PDP-C estimates:**\n\n``` {r table5, echo=F}\nkable(m5$coefficients)\n```\n\n**PDP-A estimates:**\n\n``` {r table6, echo=F}\nkable(m6$coefficients)\n```\n\n### 5. Make composite for anxiety in Study 2\n\n``` {r composite, echo = F}\nanxDat = read.delim(\"Study2_questDat.txt\")\nqplot(x=Var1, y=Var2, data=melt(cor(filter(anxDat, Subject != 87)[c(3:6, 8:18)])), fill=value, geom=\"tile\") # sub 87 doesn't have data for the last four questions\n\nhist(anxDat$Anx_composite, main = \"Histogram for anxiety composite\")\n```\n\nComposite is composed of 8 items (standardized before averaged together), alpha = .91\n\nLook at correlation between first and second blocks:  \n``` {r composite2, echo = F, warning=F}\n\nanxDat$Task = \"APT\"\nanxDat$Task[grep(\"WIT\", anxDat$blockName)] = \"WIT\"\n\nblock1 = anxDat[grep(1, anxDat$blockName),]\nblock2 = anxDat[grep(2, anxDat$blockName),]\n\nblock1 = select(block1, Subject, Task, Anx_composite) %>% \n  rename(Anx_composite1 = Anx_composite)\nblock2 = select(block2, Subject, Task, Anx_composite) %>% \n  rename(Anx_composite2 = Anx_composite)\n\nsepBlock = cbind(block1, select(block2, Anx_composite2))\n\nggplot(sepBlock, aes(Anx_composite1, Anx_composite2, color = Task)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n  geom_smooth(method=\"lm\") +\n  labs(x = \"Block 1\", y = \"Block 2\")\n\n# have to take sub 87 out for correlation, has missing data\n         \n```\n\nThe correlation between the anxiety composite score on the first block and the second block is `r cor(sepBlock$Anx_composite1[sepBlock$Subject !=87], sepBlock$Anx_composite2[sepBlock$Subject !=87])`.  \n\n### 8. Look at relationship between anxiety and PDP-A/PDP-C\nAnxiety composite scores were averaged across blocks, so each participant has one anxiety score per task.\n\n``` {r anx, echo=F}\ncollapseBlock = select(anxDat, Subject, Task, Anx_composite) %>% \n  group_by(Subject, Task) %>% \n  summarise_each(funs(mean(., na.rm=T))) %>% \n  as.data.frame()\n\n# add anxiety scores to s2.wide, which has PDP-C, PDP-A, Observer, and IMS\ns2.wide$Anx_composite = NA\nfor (i in unique(s2.wide$Subject)) {\n  for (t in c(\"WIT\", \"APT\")) {\n    s2.wide$Anx_composite[s2.wide$Subject == i & s2.wide$Task == t] = collapseBlock$Anx_composite[collapseBlock$Subject == i & collapseBlock$Task == t]\n  }\n}\n\nggplot(s2.wide, aes(scale(Anx_composite), MeanC, color = Task, shape = Task)) +\n  geom_point() +\n  geom_smooth(method=\"lm\") +\n  scale_color_manual(values=c(\"black\", \"forestgreen\")) +\n  scale_shape_manual(values=c(1,2)) +\n  labs(x=\"Anxiety composite score\", y = \"PDP-C\") +\n#  ggtitle(\"Anxiety predicting PDP-C\") +  \n  theme_bw() +\n  theme(panel.grid.major = element_line(color = \"white\"),\n        panel.grid.minor = element_line(color = \"white\"),\n        strip.text.x = element_text(face = \"bold\", size = 14),\n        strip.background = element_rect(fill = \"grey98\"),\n        axis.text.x = element_text(size = 16),\n        axis.text.y = element_text(size = 16),\n        axis.title.x = element_text(size = 20),\n        axis.title.y = element_text(size = 20))\nggsave(\"./Figures/AnxPredictingPDPC.tiff\")\n\nlmer(MeanC ~ scale(Anx_composite)*Task + (1|Subject), data = s2.wide) %>% summary()\n\nggplot(s2.wide, aes(scale(Anx_composite), AResid, color = Task, shape = Task)) +\n  geom_point() +\n  geom_smooth(method=\"lm\") +\n  scale_color_manual(values=c(\"black\", \"forestgreen\")) +\n  scale_shape_manual(values=c(1,2)) +\n  labs(x=\"Anxiety composite score\", y = \"PDP-A\") +\n#  ggtitle(\"Anxiety predicting PDP-A\") +  \n  theme_bw() +\n  theme(panel.grid.major = element_line(color = \"white\"),\n        panel.grid.minor = element_line(color = \"white\"),\n        strip.text.x = element_text(face = \"bold\", size = 14),\n        strip.background = element_rect(fill = \"grey98\"),\n        axis.text.x = element_text(size = 16),\n        axis.text.y = element_text(size = 16),\n        axis.title.x = element_text(size = 20),\n        axis.title.y = element_text(size = 20))\nggsave(\"./Figures/AnxPredictingPDPA.tiff\")\n\nlmer(AResid ~ scale(Anx_composite)*Task + (1|Subject), data = s2.wide) %>% summary()\n\n```\n\n\n### 9. Look at relationship between IMS and anxiety, as a function of observer\n\n\n``` {r IMS, echo=F}\n\nggplot(s2.wide, aes(scale(IMS), Anx_composite, color = Observer, shape = Observer)) +\n  facet_wrap(~Task) +\n  geom_point() +\n  geom_smooth(method=\"lm\") +\n  scale_color_manual(values=c(\"dodgerblue\", \"darkblue\")) +\n  scale_shape_manual(values=c(1,2)) +\n  labs(x = \"IMS\", y = \"Anxiety composite score\") +\n  theme_bw() +\n  theme(panel.grid.major = element_line(color = \"white\"),\n        panel.grid.minor = element_line(color = \"white\"),\n        strip.text.x = element_text(face = \"bold\", size = 14),\n        strip.background = element_rect(fill = \"grey98\"),\n        axis.text.x = element_text(size = 16),\n        axis.text.y = element_text(size = 16),\n        axis.title.x = element_text(size = 20),\n        axis.title.y = element_text(size = 20))\nggsave(\"./Figures/IMSxObsPredictingAnx.tiff\", width=8, height=6, unit=\"in\")\n\nlmer(scale(Anx_composite) ~ scale(IMS)*Observer*Task + (1|Subject), data = s2.wide) %>% summary()\n\n```\n\n### 10. Look at relationship between EMS and anxiety, as a function of observer\n\n``` {r EMS, echo=F}\n# add IMS data\nEMS = read.delim(\"Study2_experimentalTrials.txt\") %>% \n  filter(blockName == \"WIT_1\", SubTrial == 1) %>% \n  select(Subject, EMS)\n\ns2.wide$EMS = NA\nfor (k in EMS$Subject[!(is.na(EMS$EMS))]) {\n  s2.wide$EMS[s2.wide$Subject == k] = EMS$EMS[EMS$Subject == k]\n}\n\nggplot(s2.wide, aes(scale(EMS), Anx_composite, color = Observer, shape = Observer)) +\n  facet_wrap(~Task) +\n  geom_point() +\n  geom_smooth(method=\"lm\") +\n  scale_color_manual(values=c(\"red\", \"darkred\")) +\n  scale_shape_manual(values=c(1,2)) +\n  labs(x = \"EMS\", y = \"Anxiety composite score\") +\n  theme_bw() +\n  theme(panel.grid.major = element_line(color = \"white\"),\n        panel.grid.minor = element_line(color = \"white\"),\n        strip.text.x = element_text(face = \"bold\", size = 14),\n        strip.background = element_rect(fill = \"grey98\"),\n        axis.text.x = element_text(size = 16),\n        axis.text.y = element_text(size = 16),\n        axis.title.x = element_text(size = 20),\n        axis.title.y = element_text(size = 20))\nggsave(\"./Figures/EMSxObsPredictingAnx.tiff\", width=8, height=6, unit=\"in\")\n\nlmer(scale(Anx_composite) ~ scale(EMS)*Observer*Task + (1|Subject), data = s2.wide) %>% summary()\n\n\n```\n\n### 11. Look at relationship between IMS-EMS and anxiety, as a function of observer\n\n``` {r IMS-EMS, echo=F}\n\ns2.wide$IMS.EMS.diff = s2.wide$IMS - s2.wide$EMS\n\nhist(s2.wide$IMS.EMS.diff)\n\nggplot(s2.wide, aes(scale(IMS.EMS.diff), Anx_composite, color = Observer, shape = Observer)) +\n  facet_wrap(~Task) +\n  geom_point() +\n  geom_smooth(method=\"lm\") +\n  scale_color_manual(values=c(\"orchid\", \"purple\")) +\n  scale_shape_manual(values=c(1,2)) +\n  labs(x = \"IMS minus EMS\", y = \"Anxiety composite score\") +\n  theme_bw() +\n  theme(panel.grid.major = element_line(color = \"white\"),\n        panel.grid.minor = element_line(color = \"white\"),\n        strip.text.x = element_text(face = \"bold\", size = 14),\n        strip.background = element_rect(fill = \"grey98\"),\n        axis.text.x = element_text(size = 16),\n        axis.text.y = element_text(size = 16),\n        axis.title.x = element_text(size = 20),\n        axis.title.y = element_text(size = 20))\n\nlmer(scale(Anx_composite) ~ scale(IMS.EMS.diff)*Observer*Task + (1|Subject), data = s2.wide) %>% summary()\n\n\n```\n\n\n",
    "created" : 1491935068953.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3202316339",
    "id" : "3B0C63B3",
    "lastKnownWriteTime" : 1502898873,
    "last_content_update" : 1502898873904,
    "path" : "~/Documents/Projects/3 Observer study/Analyses/Analyses.Rmd",
    "project_path" : "Analyses.Rmd",
    "properties" : {
        "chunk_output_type" : "console",
        "last_setup_crc32" : ""
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}