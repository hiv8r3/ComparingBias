---
title: Observer analyses (Supplemental Material)
author: Hannah, 2/19/2019
output:
  html_document:
    highlight: pygments
    theme: cerulean
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(width=140)
require(dplyr)
require(tidyr)
require(ggplot2)
require(lme4)
require(lmerTest)
require(knitr)
require(reshape2)
require(kableExtra)

```
### Analyses involving observer, IMS, and EMS that are included in SM.

**Subject exclusions match manuscript.**

Data for Study 1 was collected in Fall 2015. Data for Study 2 was collected in Fall 2016.

**In Study 1:**  
- 101 subjects participated  
- 8 subjects' AP data was discarded (see "Study1_badsubsAP.txt")  
- 9 subjects' WIT data was discarded (see "Study1_badsubsWIT.txt")    
*This left 93 subjects with AP data and 92 subjects with WIT data.*

Additionally, IMS/EMS data is missing for subs 3, 27, 53, 82, 88, 89, 90, and 101. 

**In Study 2:**  
- 206 subjects participated  
- 8 subjects' AP data was discarded (see "Study2_badsubsAP.txt")  
- 7 subjects' WIT data was discarded (see "Study2_badsubsWIT.txt")  
*This left 198 subjects with AP data and 199 subjects with WIT data.*

Additionally, IMS/EMS data is missing for 111, 189, and 201.

There were 48 trials for each condition in each task (192 trials total for each task). In Study 2, each task was split into two sections so that participants could answer anxiety questions in the middle and end of each task.


### Study 1: 
Task is effect coded (APT = -1, WIT = 1). Observer is effect coded (Absent = -1, Present = 1). IMS and EMS are both standardized.  

An IMS-EMS difference score was created to approximate the degree to which motiviation to be unbiased is internalized. A higher IMS-EMS difference score represents more internalization.  
``` {r}
# PDP estimates
s1.PDP.APT = read.delim("Study1_pdpEstimates_APT.txt")
s1.PDP.WIT = read.delim("Study1_pdpEstimates_WIT.txt")


# take out bad subs
s1.bs.APT = read.delim("Study1_badSubsAP.txt")
s1.bs.WIT = read.delim("Study1_badSubsWIT.txt")

s1.PDP.APT = s1.PDP.APT[!(s1.PDP.APT$Subject %in% s1.bs.WIT$Subject) & !(s1.PDP.APT$Subject %in% s1.bs.APT$Subject),]
s1.PDP.WIT = s1.PDP.WIT[!(s1.PDP.WIT$Subject %in% s1.bs.WIT$Subject) & !(s1.PDP.WIT$Subject %in% s1.bs.APT$Subject),]

# Add standarized estimates (depends on subjects included)
s1.PDP.APT$Cmean.scale = scale(s1.PDP.APT$C_mean)
s1.PDP.WIT$Cmean.scale = scale(s1.PDP.WIT$C_mean)
s1.PDP.APT$AResid.scale = scale(s1.PDP.APT$AResid)
s1.PDP.WIT$AResid.scale = scale(s1.PDP.WIT$AResid)

# C estimates
s1.est = rbind(select(s1.PDP.APT, Task, Subject, IMS, EMS, Observer, Cmean.scale, AResid.scale),
               select(s1.PDP.WIT, Task, Subject, IMS, EMS, Observer, Cmean.scale, AResid.scale))

# Effect code task
s1.est$Task.e = -1
s1.est$Task.e[s1.est$Task == "WIT"] = 1

# Effect code observer
s1.est$Observer.e = -1
s1.est$Observer.e[s1.est$Observer == "Present"] = 1

# add IMS-EMS diff score
s1.est$IMSEMS.diff = s1.est$IMS-s1.est$EMS

# C estimates
# Observer x Task
C1 = lmer(Cmean.scale ~ Observer*Task.e + (1|Subject), data = s1.est) %>% 
  summary()
# IMS x Task
C2 = lmer(Cmean.scale ~ scale(IMS)*Task.e + (1|Subject), data = s1.est) %>% 
  summary()
# EMS x Task
C3 = lmer(Cmean.scale ~ scale(EMS)*Task.e + (1|Subject), data = s1.est) %>% 
  summary()
# IMS-EMS x Task
C4 = lmer(Cmean.scale ~ scale(IMSEMS.diff)*Task.e + (1|Subject), data = s1.est) %>% 
  summary()

# A estimates
# Observer x Task
A1 = lmer(AResid.scale ~ Observer*Task.e + (1|Subject), data = s1.est) %>% 
  summary()
# IMS x Task
A2 = lmer(AResid.scale ~ scale(IMS)*Task.e + (1|Subject), data = s1.est) %>% 
  summary()
# EMS x Task
A3 = lmer(AResid.scale ~ scale(EMS)*Task.e + (1|Subject), data = s1.est) %>% 
  summary()
# IMS-EMS x Task
A4 = lmer(AResid.scale ~ scale(IMSEMS.diff)*Task.e + (1|Subject), data = s1.est) %>% 
  summary()
```

#### Observer x Task on PDP-C estimates  
``` {r}
table = round(C1$coefficients, digits=3) # need to keep table as an object for row_spec()
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### IMS x Task on PDP-C estimates  
``` {r}
table = round(C2$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### EMS x Task on PDP-C estimates  
``` {r}
table = round(C3$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### IMS-EMS x Task on PDP-C estimates  
``` {r}
table = round(C4$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### Observer x Task on PDP-A estimates  
``` {r}
table = round(A1$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### IMS x Task on PDP-A estimates  
``` {r}
table = round(A2$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### EMS x Task on PDP-A estimates  
``` {r}
table = round(A3$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### IMS-EMS x Task on PDP-A estimates  
``` {r}
table = round(A4$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```


### Study 2: 
Task is effect coded (APT = -1, WIT = 1). Observer is effect coded (Absent = -1, Present = 1). IMS and EMS are both standardized.  

An IMS-EMS difference score was created to approximate the degree to which motiviation to be unbiased is internalized. A higher IMS-EMS difference score represents more internalization.  
``` {r}
# PDP estimates
s2.PDP.APT = read.delim("Study2_pdpEstimates_APT.txt")
s2.PDP.WIT = read.delim("Study2_pdpEstimates_WIT.txt")

# take out bad subs
s2.bs.APT = read.delim("Study2_badSubsAP.txt")
s2.bs.WIT = read.delim("Study2_badSubsWIT.txt")

s2.PDP.APT = s2.PDP.APT[!(s2.PDP.APT$Subject %in% s2.bs.WIT$Subject) & !(s2.PDP.APT$Subject %in% s2.bs.APT$Subject),]
s2.PDP.WIT = s2.PDP.WIT[!(s2.PDP.WIT$Subject %in% s2.bs.WIT$Subject) & !(s2.PDP.WIT$Subject %in% s2.bs.APT$Subject),]

# Add standarized estimates (depends on subjects included)
s2.PDP.APT$Cmean.scale = scale(s2.PDP.APT$C_mean)
s2.PDP.WIT$Cmean.scale = scale(s2.PDP.WIT$C_mean)
s2.PDP.APT$AResid.scale = scale(s2.PDP.APT$AResid)
s2.PDP.WIT$AResid.scale = scale(s2.PDP.WIT$AResid)

# C estimates
s2.est = rbind(select(s2.PDP.APT, Task, Subject, IMS, EMS, Observer, Cmean.scale, AResid.scale),
               select(s2.PDP.WIT, Task, Subject, IMS, EMS, Observer, Cmean.scale, AResid.scale))

# Effect code task
s2.est$Task.e = -1
s2.est$Task.e[s2.est$Task == "WIT"] = 1

# Effect code observer
s2.est$Observer.e = -1
s2.est$Observer.e[s1.est$Observer == "Present"] = 1


# add IMS-EMS diff score
s2.est$IMSEMS.diff = s2.est$IMS-s2.est$EMS

# C estimates
# Observer x Task
C1 = lmer(Cmean.scale ~ Observer*Task.e + (1|Subject), data = s2.est) %>% 
  summary()
# IMS x Task
C2 = lmer(Cmean.scale ~ scale(IMS)*Task.e + (1|Subject), data = s2.est) %>% 
  summary()
# EMS x Task
C3 = lmer(Cmean.scale ~ scale(EMS)*Task.e + (1|Subject), data = s2.est) %>% 
  summary()
# IMS-EMS x Task
C4 = lmer(Cmean.scale ~ scale(IMSEMS.diff)*Task.e + (1|Subject), data = s2.est) %>% 
  summary()

# A estimates
# Observer x Task
A1 = lmer(AResid.scale ~ Observer*Task.e + (1|Subject), data = s2.est) %>% 
  summary()
# IMS x Task
A2 = lmer(AResid.scale ~ scale(IMS)*Task.e + (1|Subject), data = s2.est) %>% 
  summary()
# EMS x Task
A3 = lmer(AResid.scale ~ scale(EMS)*Task.e + (1|Subject), data = s2.est) %>% 
  summary()
# IMS-EMS x Task
A4 = lmer(AResid.scale ~ scale(IMSEMS.diff)*Task.e + (1|Subject), data = s2.est) %>% 
  summary()
```

#### Observer x Task on PDP-C estimates  
``` {r}
table = round(C1$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### IMS x Task on PDP-C estimates  
``` {r}
table = round(C2$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### EMS x Task on PDP-C estimates  
``` {r}
table = round(C3$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### IMS-EMS x Task on PDP-C estimates  
``` {r}
table = round(C4$coefficients, digits=3) 
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### Observer x Task on PDP-A estimates  
``` {r}
table = round(A1$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### IMS x Task on PDP-A estimates  
``` {r}
table = round(A2$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### EMS x Task on PDP-A estimates  
``` {r}
table = round(A3$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

#### IMS-EMS x Task on PDP-A estimates  
``` {r}
table = round(A4$coefficients, digits=3)
kable(table) %>% 
  kable_styling(full_width = F, position = "center") %>% 
  row_spec(which(table[,5] < .05), bold = T, background = "#FFFF66")
```

### Re-analysis of repeated measures ANOVA using MLM


#### Study 1:  
Only showing interaction indicating racial bias (Prime x Target). 

**WIT**  
```{r data}
# For analyses with accuracy as DV, need trials to be grouped into conditions (ie number of errors in each condition)
s1.acc = read.delim("Study1_accuracy.txt")

# separate by task
s1.acc.APT = s1.acc[s1.acc$Task == "APT",]
s1.acc.WIT = s1.acc[s1.acc$Task == "WIT",]

# remove bad subs
s1.bs.APT = read.delim("Study1_badSubsAP.txt")
s1.acc.APT = s1.acc.APT[!(s1.acc.APT$Subject %in% s1.bs.APT$Subject),]

s1.bs.WIT = read.delim("Study1_badSubsWIT.txt")
s1.acc.WIT = s1.acc.WIT[!(s1.acc.WIT$Subject %in% s1.bs.WIT$Subject),]


# Race x Valence on accuracy (WIT)
sum = lmer(Accuracy ~ PrimeType*TargetType + (TargetType|Subject), data = s1.acc.WIT) %>% 
  summary()

sum$call
sum$coefficients


```

**AP**
``` {r AP}
# Race x Valence on accuracy (APT)
sum = lmer(Accuracy ~ PrimeType*TargetType + (TargetType|Subject), data = s1.acc.APT) %>% 
  summary()

sum$call
sum$coefficients
```


#### Study 2: 
Only showing interaction indicating racial bias (Prime x Target).   
**WIT**  
```{r data2, echo = FALSE}
s2.acc = read.delim("Study2_accuracy.txt")

# separate by task
s2.acc.APT = s2.acc[s2.acc$Task == "APT",]
s2.acc.WIT = s2.acc[s2.acc$Task == "WIT",]

# remove bad subs
s2.bs.APT = read.delim("Study2_badSubsAP.txt")
s2.acc.APT = s2.acc.APT[!(s2.acc.APT$Subject %in% s2.bs.APT$Subject),]

s2.bs.WIT = read.delim("Study2_badSubsWIT.txt")
s2.acc.WIT = s2.acc.WIT[!(s2.acc.WIT$Subject %in% s2.bs.WIT$Subject),]

# Race x Valence on accuracy (WIT)
sum = lmer(Accuracy ~ PrimeType*TargetType + (TargetType|Subject), data = s2.acc.WIT) %>% 
  summary()

sum$call
sum$coefficients
```

**AP**
``` {r AP2}
# Race x Valence on accuracy (WIT)
sum = lmer(Accuracy ~ PrimeType*TargetType + (TargetType|Subject), data = s2.acc.APT) %>% 
  summary()

sum$call
sum$coefficients
```

### 2. Comparing accuracy across tasks

#### Study 1
Don't have to exclude subjects who only have data for one task (MLM doesn't require list-wise deletion).  
n = 100  

#### A. Correlation between performance bias scores on each task
No repeated measures.

#### B. Examine 3 way Prime x Target x Task interaction  
``` {r 3way.s1}
s1.acc.nobs = rbind(s1.acc.APT, s1.acc.WIT)

# See if pattern of racial bias differs across two tasks- TOTAL ERRORS
sum2 = lmer(Accuracy ~ (PrimeType*ConType*Task)+(ConType+Task|Subject), data = s1.acc.nobs) %>%
  summary()

sum2$call
sum2$coefficients

```

#### Study 2
Don't have to exclude subjects who only have data for one task (MLM doesn't require list-wise deletion).  
n = 204 

#### A. Correlation between performance bias scores on each task
No repeated measures.

#### B. Examine 3 way Prime x Target x Task interaction  
``` {r 3way.s2}
s2.acc.nobs = rbind(s2.acc.APT, s2.acc.WIT)

# See if pattern of racial bias differs across two tasks- TOTAL ERRORS
sum2 = lmer(Accuracy ~ (PrimeType*ConType*Task)+(ConType+Task|Subject), data = s2.acc.nobs) %>%
  summary()

sum2$call
sum2$coefficients

```

